import { OpenAIClient } from '@bytemain/openai-fetch';

import { startsWith } from '@/commander';
import { StringBuilder } from '@/utils';

import type { DingBot } from '../bot';
import { code, markdown } from '../message';
import { IDingInfo } from '../secrets';

import { Context, DingCommandCenter } from './types';

export function registerCommonCommand(it: DingCommandCenter) {
  it.on(
    'putData',
    async (bot: DingBot, ctx: Context<Partial<IDingInfo>>) => {
      const info = {} as IDingInfo;
      if (ctx.parsed.raw['defaultRepo']) {
        info['defaultRepo'] = ctx.parsed.raw['defaultRepo'];
      }
      await bot.kvManager.updateGroupInfo(bot.id, info);
      await bot.replyText('更新信息成功');
    },
    undefined,
    startsWith,
  );

  it.on('getGroupInfo', async (bot: DingBot) => {
    await bot.reply(
      code(
        'json',
        JSON.stringify({
          conversationId: bot.msg.conversationId,
          senderCorpId: bot.msg.senderCorpId,
        }),
      ),
    );
  });

  it.on('help', async (bot: DingBot) => {
    const text = new StringBuilder();
    const prefix = it.prefixes.filter(Boolean).join('、');
    if (prefix) {
      text.add('前缀：' + prefix);
    }

    text.add('支持的命令：', true);

    it.registry.handlers.forEach(([key, [_, compareFunc]]) => {
      text.add(`- ${key}: ${compareFunc.name}`);
    });

    it.regexRegistry.handlers.forEach(([key, [_, compareFunc]]) => {
      text.add(`- ${key}: ${compareFunc.name}`);
    });
    if (it.fallbackHandler) {
      text.add(`- *: fallbackHandler`);
    }

    await bot.replyText(text.build());
  });

  it.on('ping', async (bot: DingBot) => {
    await bot.replyText('pong');
  });

  it.all(async (bot: DingBot, ctx: Context) => {
    if (bot.env.OPENAI_API_KEY) {
      console.log('openai api key set');

      const openai = new OpenAIClient({
        apiKey: bot.env.OPENAI_API_KEY,
        options: {
          // eslint-disable-next-line @typescript-eslint/ban-ts-comment
          // @ts-ignore
          credentials: undefined,
        },
      });
      const response = await openai.createCompletion({
        model: 'text-davinci-003',
        prompt: ctx.command,
        temperature: 0.8, //A number between 0 and 1 that determines how many creative risks the engine takes when generating text.
        max_tokens: 1000, // Maximum completion length. max: 4000-prompt
        frequency_penalty: 0.7, // # between 0 and 1. The higher this value, the bigger the effort the model will make in not repeating itself.
      });
      const text = response.completion;
      if (text) {
        await bot.reply(
          markdown(
            `Reply for "${ctx.command.slice(0, 10)}"`,
            `${text.trim()}\n\n> [Generated By OpenAI GPT-3](https://beta.openai.com/docs/models/gpt-3)`,
          ),
        );
      }
    }
  });
}
