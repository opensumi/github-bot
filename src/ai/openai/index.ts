import { OpenAIClient, CompletionParams } from '@bytemain/openai-fetch';

import { DingBot } from '@/ding/bot';
import { Context } from '@/ding/commands';
import { markdown } from '@/ding/message';

import { Conversation } from '../conversation';

import { ECompletionModel } from './shared';

export class OpenAI {
  openai: OpenAIClient;
  model = ECompletionModel.GPT3;

  constructor(protected bot: DingBot, protected ctx: Context) {
    this.openai = new OpenAIClient({
      apiKey: bot.env.OPENAI_API_KEY,
      options: {
        // eslint-disable-next-line @typescript-eslint/ban-ts-comment
        // @ts-ignore
        credentials: undefined,
      },
    });
  }

  async getReplyText() {
    let text: string | undefined;

    const conversationModeEnabled =
      await this.bot.conversationKVManager.getConversationModeEnabled();
    if (conversationModeEnabled) {
      const conversation = new Conversation(this.bot, this.ctx, this);
      text = await conversation.reply();
    } else {
      text = await this.createCompletion(this.ctx.command);
    }
    return text;
  }

  async createCompletion(
    prompt: string,
    options?: {
      stop?: string | string[];
      max_tokens?: number;
    },
  ): Promise<string | undefined> {
    const model =
      await this.bot.conversationKVManager.getConversationPreferredModel();

    const params = {
      model: model,
      prompt: prompt,
      temperature: 0.8,
      top_p: 1.0,
      presence_penalty: 1.0,
      frequency_penalty: 0.5,
      max_tokens: options?.max_tokens || 1024,
    } as CompletionParams;
    if (options?.stop) {
      params.stop = options.stop;
    }
    const response = await this.openai.createCompletion(params);
    const text = response.completion;

    return text;
  }

  async reply(text: string): Promise<void> {
    if (text) {
      await this.bot.reply(
        markdown(
          text.slice(0, 30),
          `${text.trim()}\n\n> Generated By OpenAI GPT-3`,
        ),
      );
    }
  }
}
